{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b250ee5",
   "metadata": {},
   "source": [
    "### Next Steps for GraphSAGE Pipeline:\n",
    "1. Set up train/validation/test splits\n",
    "2. Implement heterogeneous GraphSAGE model\n",
    "3. Train and evaluate venue prediction performance (supervised)\n",
    "4. Make train/validation/test sets inductive. \n",
    "5. Use an unsupervised GraphSAGE to learn node embeddings\n",
    "6. Implement a simple classifcation head to perform venue prediction (self supervised learning).\n",
    "7. Extend model to perform link prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb0763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np # linear algebra\n",
    "import os # accessing directory structure\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import SAGEConv, GraphSAGE, to_hetero\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "from src.dataset_to_inductive import to_inductive\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6da643d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\n",
      "\n",
      "Loading OGB-MAG dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_23704\\590239285.py:14: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  data = dataset.data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset loaded successfully!\n",
      "Data saved in: c:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\data\\ogb_mag\n"
     ]
    }
   ],
   "source": [
    "# Load the OGB-MAG dataset\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"\\nLoading OGB-MAG dataset...\")\n",
    "\n",
    "# Define data path relative to the workspace folder\n",
    "data_path = os.path.join('data', 'ogb_mag')\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "# Load dataset\n",
    "transform = [\"to_undirected\"] # insert preprocessing steps that should be applied to the data. It is common to include reverse edges.\n",
    "preprocess = \"transe\" # specify how to obtain initial embeddings for nodes (\"transe\", \"metapath2vec\") are some options.\n",
    "dataset = OGB_MAG(root=data_path, preprocess=preprocess, transform=transform)\n",
    "# Get the heterogeneous graph data. Is of type HeteroData.\n",
    "data = dataset.data\n",
    "\n",
    "node_type = \"paper\" # target node type\n",
    "data_inductive = to_inductive(data.clone(), node_type)\n",
    "\n",
    "\n",
    "print(f\"\\nDataset loaded successfully!\")\n",
    "print(f\"Data saved in: {os.path.abspath(data_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "692c6466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cpu\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(torch. __version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfd052e",
   "metadata": {},
   "source": [
    "## Data Loaders\n",
    "\n",
    "Create NeighborLoader for mini-batch training with neighborhood sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "542c60d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader: 615 batches\n",
      "Val loader: 0 batches\n",
      "Test loader: 0 batches\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest loader: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m batches\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Sample a batch to inspect structure\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m sample_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSample batch structure:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode types: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_batch\u001b[38;5;241m.\u001b[39mnode_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 732\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    738\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    787\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 788\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    790\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\.venv\\lib\\site-packages\\torch_geometric\\loader\\node_loader.py:147\u001b[0m, in \u001b[0;36mNodeLoader.collate_fn\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Samples a subgraph from a batch of input nodes.\"\"\"\u001b[39;00m\n\u001b[0;32m    145\u001b[0m input_data: NodeSamplerInput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_data[index]\n\u001b[1;32m--> 147\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_sampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_per_worker:  \u001b[38;5;66;03m# Execute `filter_fn` in the worker process\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_fn(out)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\.venv\\lib\\site-packages\\torch_geometric\\sampler\\neighbor_sampler.py:403\u001b[0m, in \u001b[0;36mNeighborSampler.sample_from_nodes\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msample_from_nodes\u001b[39m(\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    401\u001b[0m     inputs: NodeSamplerInput,\n\u001b[0;32m    402\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[SamplerOutput, HeteroSamplerOutput]:\n\u001b[1;32m--> 403\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mnode_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubgraph_type \u001b[38;5;241m==\u001b[39m SubgraphType\u001b[38;5;241m.\u001b[39mbidirectional:\n\u001b[0;32m    405\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mto_bidirectional(keep_orig_edges\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_orig_edges)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\.venv\\lib\\site-packages\\torch_geometric\\sampler\\neighbor_sampler.py:815\u001b[0m, in \u001b[0;36mnode_sample\u001b[1;34m(inputs, sample_fn)\u001b[0m\n\u001b[0;32m    812\u001b[0m     seed \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mnode\n\u001b[0;32m    813\u001b[0m     seed_time \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mtime\n\u001b[1;32m--> 815\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43msample_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    816\u001b[0m out\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m (inputs\u001b[38;5;241m.\u001b[39minput_id, inputs\u001b[38;5;241m.\u001b[39mtime)\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\.venv\\lib\\site-packages\\torch_geometric\\sampler\\neighbor_sampler.py:512\u001b[0m, in \u001b[0;36mNeighborSampler._sample\u001b[1;34m(self, seed, seed_time, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m     num_sampled_nodes \u001b[38;5;241m=\u001b[39m num_sampled_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requires \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyg-lib\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch-sparse\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_direction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    516\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m col, row\n",
      "\u001b[1;31mImportError\u001b[0m: 'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'"
     ]
    }
   ],
   "source": [
    "# Create NeighborLoader for mini-batch training\n",
    "# This implements neighborhood sampling as described in the GraphSAGE paper\n",
    "\n",
    "# Define sampling parameters\n",
    "num_neighbors = [10, 10]  # Sample 10 neighbors at each of 2 layers (as in GraphSAGE paper)\n",
    "batch_size = 1024\n",
    "\n",
    "# Create train loader\n",
    "train_loader = NeighborLoader(\n",
    "    data_inductive,\n",
    "    num_neighbors=num_neighbors,\n",
    "    batch_size=batch_size,\n",
    "    input_nodes=('paper', data_inductive['paper'].train_mask),\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Create validation loader\n",
    "val_loader = NeighborLoader(\n",
    "    data_inductive,\n",
    "    num_neighbors=num_neighbors,\n",
    "    batch_size=batch_size,\n",
    "    input_nodes=('paper', data_inductive['paper'].val_mask),\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Create test loader\n",
    "test_loader = NeighborLoader(\n",
    "    data_inductive,\n",
    "    num_neighbors=num_neighbors,\n",
    "    batch_size=batch_size,\n",
    "    input_nodes=('paper', data_inductive['paper'].test_mask),\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(f\"Train loader: {len(train_loader)} batches\")\n",
    "print(f\"Val loader: {len(val_loader)} batches\")\n",
    "print(f\"Test loader: {len(test_loader)} batches\")\n",
    "\n",
    "# Sample a batch to inspect structure\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"\\nSample batch structure:\")\n",
    "print(f\"Node types: {sample_batch.node_types}\")\n",
    "print(f\"Edge types: {sample_batch.edge_types}\")\n",
    "print(f\"Paper nodes in batch: {sample_batch['paper'].num_nodes}\")\n",
    "print(f\"Batch size (target nodes): {sample_batch['paper'].batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ae807",
   "metadata": {},
   "source": [
    "## GraphSAGE Model Implementation\n",
    "\n",
    "Implementing the GraphSAGE architecture as described in \"Inductive Representation Learning on Large Graphs\" (Hamilton et al., 2017).\n",
    "\n",
    "Key features:\n",
    "- **Neighborhood Aggregation**: Sample and aggregate features from node neighborhoods\n",
    "- **Layer-wise Propagation**: Stack multiple GraphSAGE layers\n",
    "- **Heterogeneous Support**: Handle multiple node and edge types using `to_hetero`\n",
    "- **Mean Aggregator**: Use mean aggregation (default in SAGEConv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9232ec16",
   "metadata": {},
   "source": [
    "### Important Note on Heterogeneous Graphs\n",
    "\n",
    "**Problem**: When converting to heterogeneous graphs with `to_hetero`, all node types must be updated during message passing. However, some node types (like `'author'`, `'institution'`, `'field_of_study'`) don't have initial features in OGB-MAG.\n",
    "\n",
    "**Solution**: Add a `Linear` layer at the beginning that creates embeddings for ALL node types. The `-1` in `torch.nn.Linear(-1, hidden_channels)` allows PyTorch Geometric to automatically infer the input dimension for each node type after `to_hetero` conversion, creating separate linear layers for each node type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb45d154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\.venv\\lib\\site-packages\\torch_geometric\\nn\\to_hetero_transformer.py:151: UserWarning: There exist node types ({'author'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behavior.\n",
      "  self.validate()\n",
      "c:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\.venv\\lib\\site-packages\\torch_geometric\\nn\\to_hetero_transformer.py:120: UserWarning: Found function 'dropout' with keyword argument 'training'. During FX tracing, this will likely be baked in as a constant value. Consider replacing this function by a module to properly encapsulate its training flag.\n",
      "  return transformer.transform()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot generate a graph node 'relu' for type 'author' since it does not exist. Please make sure that all node types get updated during message passing.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 45\u001b[0m\n\u001b[0;32m     37\u001b[0m model \u001b[38;5;241m=\u001b[39m MyGraphSAGE(\n\u001b[0;32m     38\u001b[0m     hidden_channels\u001b[38;5;241m=\u001b[39mhidden_channels,\n\u001b[0;32m     39\u001b[0m     out_channels\u001b[38;5;241m=\u001b[39mnum_classes,\n\u001b[0;32m     40\u001b[0m     num_layers\u001b[38;5;241m=\u001b[39mnum_layers,\n\u001b[0;32m     41\u001b[0m     dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Convert to heterogeneous model. Makes GraphSAGE work for different node and edge types in the same graph\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mto_hetero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_inductive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel initialized with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_channels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m hidden channels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of output classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\.venv\\lib\\site-packages\\torch_geometric\\nn\\to_hetero_transformer.py:120\u001b[0m, in \u001b[0;36mto_hetero\u001b[1;34m(module, metadata, aggr, input_map, debug)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Converts a homogeneous GNN model into its heterogeneous equivalent in\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03mwhich node representations are learned for each node type in\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m:obj:`metadata[0]`, and messages are exchanged between each edge type in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m        transformation in debug mode. (default: :obj:`False`)\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m transformer \u001b[38;5;241m=\u001b[39m ToHeteroTransformer(module, metadata, aggr, input_map, debug)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\.venv\\lib\\site-packages\\torch_geometric\\nn\\fx.py:168\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m is_global_pooling_op(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, op, node\u001b[38;5;241m.\u001b[39mtarget):\n\u001b[0;32m    167\u001b[0m         op \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_global_pooling_module\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# Remove all unused nodes in the computation graph, i.e., all nodes\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# which have been replaced by node type-wise or edge type-wise variants\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# but which are still present in the computation graph.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# We do this by iterating over the computation graph in reversed order,\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# and try to remove every node. This does only succeed in case there\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# are no users of that node left in the computation graph.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnodes)):\n",
      "File \u001b[1;32mc:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\.venv\\lib\\site-packages\\torch_geometric\\nn\\to_hetero_transformer.py:321\u001b[0m, in \u001b[0;36mToHeteroTransformer.call_function\u001b[1;34m(self, node, target, name)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minserting_after(node)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_edge_level(node))]:\n\u001b[1;32m--> 321\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_args_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mcreate_node(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_function\u001b[39m\u001b[38;5;124m'\u001b[39m, target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[0;32m    323\u001b[0m                                  args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m    324\u001b[0m                                  name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey2str(key)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minserting_after(out)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\.venv\\lib\\site-packages\\torch_geometric\\nn\\to_hetero_transformer.py:418\u001b[0m, in \u001b[0;36mToHeteroTransformer.map_args_kwargs\u001b[1;34m(self, node, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m--> 418\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_recurse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {k: _recurse(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args, kwargs\n",
      "File \u001b[1;32mc:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\.venv\\lib\\site-packages\\torch_geometric\\nn\\to_hetero_transformer.py:418\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m--> 418\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43m_recurse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39margs)\n\u001b[0;32m    419\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {k: _recurse(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args, kwargs\n",
      "File \u001b[1;32mc:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\.venv\\lib\\site-packages\\torch_geometric\\nn\\to_hetero_transformer.py:404\u001b[0m, in \u001b[0;36mToHeteroTransformer.map_args_kwargs.<locals>._recurse\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    400\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_by_name(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey2str(key[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    401\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_by_name(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey2str(key[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    402\u001b[0m         )\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 404\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot generate a graph node \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    405\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m since it does not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    406\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexist. Please make sure that all \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    407\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode types get updated during message \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    408\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: _recurse(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot generate a graph node 'relu' for type 'author' since it does not exist. Please make sure that all node types get updated during message passing."
     ]
    }
   ],
   "source": [
    "class MyGraphSAGE(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    GraphSAGE model for node classification on heterogeneous graphs.\n",
    "    \n",
    "    Architecture:\n",
    "    - Linear projections for each node type (handles nodes without features)\n",
    "    - Two GraphSAGE convolutional layers\n",
    "    - ReLU activation between layers\n",
    "    - Dropout for regularization\n",
    "    - Supports heterogeneous graphs via to_hetero conversion\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_channels, out_channels, num_layers=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Linear layer to project input features to hidden_channels\n",
    "        # Use -1 to let PyG infer the input dimension for each node type\n",
    "        self.lin = torch.nn.Linear(-1, hidden_channels)\n",
    "        \n",
    "        # Define GraphSAGE layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(SAGEConv((-1, -1), hidden_channels))\n",
    "        self.convs.append(SAGEConv((-1, -1), out_channels))\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # Project input features to hidden dimension\n",
    "        x = self.lin(x).relu()\n",
    "        \n",
    "        # Apply GraphSAGE layers\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "hidden_channels = 256\n",
    "num_classes = int(data_inductive['paper'].y.max().item() + 1)\n",
    "num_layers = 2\n",
    "\n",
    "# Create base model\n",
    "model = MyGraphSAGE(\n",
    "    hidden_channels=hidden_channels,\n",
    "    out_channels=num_classes,\n",
    "    num_layers=num_layers,\n",
    "    dropout=0.5\n",
    ")\n",
    "\n",
    "# Convert to heterogeneous model. Makes GraphSAGE work for different node and edge types in the same graph\n",
    "# aggr='mean' is more standard for GraphSAGE\n",
    "model = to_hetero(model, data_inductive.metadata(), aggr='mean')\n",
    "\n",
    "print(f\"Model initialized with {hidden_channels} hidden channels\")\n",
    "print(f\"Number of output classes: {num_classes}\")\n",
    "print(f\"Number of layers: {num_layers}\")\n",
    "print(f\"\\nModel structure:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d53f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation functions\n",
    "def train_epoch(model, loader, optimizer, device):\n",
    "    \"\"\"Train the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_examples = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        out = model(batch.x_dict, batch.edge_index_dict)\n",
    "        \n",
    "        # Get predictions for target nodes only (papers in the batch)\n",
    "        pred = out['paper'][:batch['paper'].batch_size]\n",
    "        y = batch['paper'].y[:batch['paper'].batch_size]\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(pred, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        total_loss += loss.item() * pred.size(0) # float(loss)\n",
    "        total_correct += int((pred.argmax(dim=-1) == y).sum())\n",
    "        total_examples += pred.size(0)\n",
    "    \n",
    "    return total_loss / total_examples, total_correct / total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_examples = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        out = model(batch.x_dict, batch.edge_index_dict)\n",
    "        \n",
    "        # Get predictions for target nodes only\n",
    "        pred = out['paper'][:batch['paper'].batch_size]\n",
    "        y = batch['paper'].y[:batch['paper'].batch_size]\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(pred, y)\n",
    "        \n",
    "        # Track metrics\n",
    "        total_loss += float(loss) * pred.size(0)\n",
    "        total_correct += int((pred.argmax(dim=-1) == y).sum())\n",
    "        total_examples += pred.size(0)\n",
    "    \n",
    "    return total_loss / total_examples, total_correct / total_examples\n",
    "\n",
    "print(\"Training and evaluation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44de0d3",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Train the supervised GraphSAGE model for venue (label) prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 50\n",
    "best_val_acc = 0\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_acc': []\n",
    "}\n",
    "\n",
    "print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, device)\n",
    "    \n",
    "    # Evaluate\n",
    "    val_loss, val_acc = evaluate(model, val_loader, device)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Print progress\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:3d} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"Training complete! Best validation accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "# Load best model for testing\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_loader, device)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e222ec",
   "metadata": {},
   "source": [
    "## Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3e5730",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot loss\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot accuracy\n",
    "axes[1].plot(history['train_acc'], label='Train Acc', marker='o')\n",
    "axes[1].plot(history['val_acc'], label='Val Acc', marker='s')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Training and Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphSSL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
