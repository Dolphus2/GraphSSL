{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a2802a",
   "metadata": {},
   "source": [
    "# GraphSSL Demonstration\n",
    "\n",
    "I recommend running the main pipeline using the command line interface or by running the shell script run_examples.sh. Here is a Jupyter notebook for compleness.\n",
    "\n",
    "Train and evaluate graph representation learning models on OGBN-MAG dataset.\n",
    "\n",
    "**Estimated Runtime**: ~10 hours on RTX 3060 (100 epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6c3ad3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08ea69bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\.venv\\Scripts\\python.exe: No module named pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "914006ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.8.0+cu126\n",
      "CUDA: True\n",
      "GPU: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "# Add project root to sys path just in case. It is recommended to install the project as a pip package by running the top block.\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'scripts' else Path.cwd()\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "from graphssl.main import run_pipeline\n",
    "from graphssl.utils.args_utils import parse_args\n",
    "import wandb\n",
    "wandb.init(mode=\"disabled\")\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fcfc11",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44644eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: supervised_node\n",
      "Objective: supervised_node_classification\n",
      "Results will be saved to: c:\\Users\\gabri\\GTFO_Onedrive\\DTU_Code\\GraphSSL\\results\\demo_supervised_node_20251208_171952\n",
      "\n",
      "Estimated runtime on RTX 3060: ~10 hours for 10 epochs (with downstream evaluation)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "EXPERIMENT = \"supervised_node\"\n",
    "# EXPERIMENT = \"ssl_node_sce\"\n",
    "# EXPERIMENT = \"ssl_node_mse\"\n",
    "# EXPERIMENT = \"ssl_edge\"\n",
    "# EXPERIMENT = \"ssl_tarpfp\"\n",
    "\n",
    "CONFIG = {\n",
    "    \"data_root\": str(project_root / \"data\"),\n",
    "    \"results_root\": str(project_root / \"results\" / f\"demo_{EXPERIMENT}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"),\n",
    "    \"target_node\": \"paper\",\n",
    "    \"target_edge_type\": \"paper,has_topic,field_of_study\",\n",
    "    \"hidden_channels\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"num_neighbors\": [30, 30],\n",
    "    \"batch_size\": 1024,\n",
    "    \"epochs\": 10,\n",
    "    \"lr\": 0.001,\n",
    "    \"dropout\": 0.5,\n",
    "    \"patience\": 5,\n",
    "    \"num_workers\": 4,\n",
    "    \"weight_decay\": 0,\n",
    "    \"log_interval\": 10,\n",
    "    \"seed\": 42,\n",
    "    \"edge_msg_pass_prop\": [0, 0, 0],\n",
    "    \"extract_embeddings\": True,\n",
    "    \"downstream_eval\": True,\n",
    "    \"downstream_task\": \"both\",\n",
    "    \"downstream_n_runs\": 2,\n",
    "    \"downstream_hidden_dim\": 128,\n",
    "    \"downstream_num_layers\": 2,\n",
    "    \"downstream_dropout\": 0.5,\n",
    "    \"multiclass_batch_size\": 256,\n",
    "    \"downstream_node_epochs\": 10,\n",
    "    \"downstream_link_epochs\": 1,\n",
    "    \"downstream_patience\": 4,\n",
    "    \"downstream_lr\": 0.0001,\n",
    "    # Defaults from parse_args\n",
    "    \"model_path\": None,\n",
    "    \"preprocess\": \"metapath2vec\",\n",
    "    \"metapath2vec_embeddings_path\": \"embedding.pt\",\n",
    "    \"loss_fn\": \"mse\",\n",
    "    \"mer_weight\": 1.0,\n",
    "    \"tar_weight\": 1.0,\n",
    "    \"pfp_weight\": 1.0,\n",
    "    \"tar_temperature\": 0.5,\n",
    "    \"mask_ratio\": 0.5,\n",
    "    \"neg_sampling_ratio\": 1.0,\n",
    "    \"aggr\": \"mean\",\n",
    "    \"aggr_rel\": \"sum\",\n",
    "    \"use_batchnorm\": True,\n",
    "    \"node_inductive\": True,\n",
    "    \"dependent_node_edge_data_split\": True,\n",
    "    \"lambda_tar\": 1.0,\n",
    "    \"lambda_pfp\": 0.0,\n",
    "    \"disable_tqdm\": False,\n",
    "    \"log_level\": \"INFO\",\n",
    "    \"downstream_batch_size\": 1024,\n",
    "    \"downstream_weight_decay\": 0,\n",
    "    \"downstream_neg_samples\": 1,\n",
    "    \"test_mode\": True,\n",
    "    \"test_max_nodes\": 5000,\n",
    "}\n",
    "\n",
    "# Experiment-Specific Parameters\n",
    "if EXPERIMENT == \"supervised_node\":\n",
    "    CONFIG.update({\n",
    "        \"objective_type\": \"supervised_node_classification\",\n",
    "        \"use_feature_decoder\": True,\n",
    "        \"use_edge_decoder\": True,\n",
    "    })\n",
    "    \n",
    "elif EXPERIMENT == \"ssl_node_sce\":\n",
    "    CONFIG.update({\n",
    "        \"objective_type\": \"self_supervised_node\",\n",
    "        \"loss_fn\": \"sce\",\n",
    "        \"mask_ratio\": 0.5,\n",
    "        \"use_feature_decoder\": True,\n",
    "        \"use_edge_decoder\": True,\n",
    "        \"patience\": 20,\n",
    "        \"downstream_link_epochs\": 3,\n",
    "        \"downstream_patience\": 20,\n",
    "    })\n",
    "    \n",
    "elif EXPERIMENT == \"ssl_node_mse\":\n",
    "    CONFIG.update({\n",
    "        \"objective_type\": \"self_supervised_node\",\n",
    "        \"loss_fn\": \"mse\",\n",
    "        \"mask_ratio\": 0.5,\n",
    "        \"use_feature_decoder\": True,\n",
    "        \"use_edge_decoder\": True,\n",
    "    })\n",
    "    \n",
    "elif EXPERIMENT == \"ssl_edge\":\n",
    "    CONFIG.update({\n",
    "        \"objective_type\": \"self_supervised_edge\",\n",
    "        \"neg_sampling_ratio\": 1.0,\n",
    "        \"use_feature_decoder\": True,\n",
    "        \"use_edge_decoder\": True,\n",
    "    })\n",
    "    \n",
    "elif EXPERIMENT == \"ssl_tarpfp\":\n",
    "    CONFIG.update({\n",
    "        \"objective_type\": \"self_supervised_tarpfp\",\n",
    "        \"lambda_tar\": 1.0,\n",
    "        \"lambda_pfp\": 1.0,\n",
    "        \"mask_ratio\": 0.5,\n",
    "        \"neg_sampling_ratio\": 1.0,\n",
    "        \"tar_temperature\": 0.5,\n",
    "        \"use_feature_decoder\": True,\n",
    "        \"use_edge_decoder\": True,\n",
    "        \"metapath2vec_embeddings_path\": \"pos_embedding.pt\",\n",
    "    })\n",
    "\n",
    "print(f\"Experiment: {EXPERIMENT}\")\n",
    "print(f\"Objective: {CONFIG['objective_type']}\")\n",
    "print(f\"Results will be saved to: {CONFIG['results_root']}\")\n",
    "print(f\"\\nEstimated runtime on RTX 3060: ~10 hours for {CONFIG['epochs']} epochs (with downstream evaluation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e72aa5",
   "metadata": {},
   "source": [
    "## Training\n",
    "Run the main experiment pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad20db98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GraphSSL - Supervised Learning Pipeline\n",
      "Task: Venue Prediction on OGB_MAG Dataset\n",
      "================================================================================\n",
      "\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3060\n",
      "CUDA Version: 12.6\n",
      "\n",
      "================================================================================\n",
      "Step 1: Loading Dataset\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Step 2: Creating Data Loaders\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Step 2: Creating Data Loaders\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Step 3: Creating Training Objective\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Step 4: Creating Model\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Step 5: Setting up Optimizer\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Step 6: Training Model\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Step 3: Creating Training Objective\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Step 4: Creating Model\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Step 5: Setting up Optimizer\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Step 6: Training Model\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/10 | Train Loss: 5.9513 | Train Acc: 0.0056 | Val Loss: 5.8363 | Val Acc: 0.0158 | Time: 16.93s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2/10 | Train Loss: 5.7476 | Train Acc: 0.0131 | Val Loss: 5.7919 | Val Acc: 0.0181 | Time: 14.99s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   3/10 | Train Loss: 5.5700 | Train Acc: 0.0310 | Val Loss: 5.7266 | Val Acc: 0.0226 | Time: 14.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4/10 | Train Loss: 5.4421 | Train Acc: 0.0387 | Val Loss: 5.6384 | Val Acc: 0.0249 | Time: 15.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5/10 | Train Loss: 5.3128 | Train Acc: 0.0507 | Val Loss: 5.5265 | Val Acc: 0.0430 | Time: 15.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   6/10 | Train Loss: 5.2214 | Train Acc: 0.0549 | Val Loss: 5.3901 | Val Acc: 0.0566 | Time: 14.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   7/10 | Train Loss: 5.1137 | Train Acc: 0.0657 | Val Loss: 5.2513 | Val Acc: 0.0701 | Time: 13.99s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   8/10 | Train Loss: 5.0499 | Train Acc: 0.0737 | Val Loss: 5.1310 | Val Acc: 0.0747 | Time: 14.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   9/10 | Train Loss: 4.9685 | Train Acc: 0.0855 | Val Loss: 5.0213 | Val Acc: 0.0769 | Time: 15.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10/10 | Train Loss: 4.9118 | Train Acc: 0.0902 | Val Loss: 4.9368 | Val Acc: 0.0747 | Time: 14.20s\n",
      "\n",
      "================================================================================\n",
      "Step 7: Testing Model\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Step 7: Testing Model\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Step 8: Saving Results\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Step 9: Extracting Embeddings\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Step 10: Downstream Evaluation\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  91%|█████████ | 39/43 [00:07<00:00, 30.04it/s]"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "args = argparse.Namespace(**CONFIG)\n",
    "run_pipeline(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c934a974",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248f6c73",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results_dir = \u001b[43mPath\u001b[49m(CONFIG[\u001b[33m'\u001b[39m\u001b[33mresults_root\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      2\u001b[39m history = torch.load(results_dir / \u001b[33m\"\u001b[39m\u001b[33mtraining_history.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m history:\n",
      "\u001b[31mNameError\u001b[39m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "results_dir = Path(CONFIG['results_root'])\n",
    "history = torch.load(results_dir / \"training_history.pt\")\n",
    "\n",
    "if 'train_loss' in history:\n",
    "    print(f\"Train Loss: {history['train_loss'][-1]:.4f}\")\n",
    "    print(f\"Val Loss: {history['val_loss'][-1]:.4f}\")\n",
    "if 'val_acc' in history:\n",
    "    print(f\"Best Val Acc: {max(history['val_acc']):.4f}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "if 'train_loss' in history:\n",
    "    axes[0].plot(history['train_loss'], label='Train')\n",
    "    axes[0].plot(history['val_loss'], label='Val')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "if 'val_acc' in history:\n",
    "    axes[1].plot(history['val_acc'])\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661a7d8",
   "metadata": {},
   "source": [
    "## Downstream Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b84b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "downstream_results = torch.load(results_dir / \"downstream_node_results.pt\")\n",
    "\n",
    "if 'node_classification' in downstream_results:\n",
    "    r = downstream_results['node_classification']\n",
    "    print(\"Node Classification:\")\n",
    "    print(f\"  Test Acc: {r['test_acc_mean']:.4f} ± {r['test_acc_std']:.4f}\")\n",
    "    print(f\"  Test F1:  {r['test_f1_mean']:.4f} ± {r['test_f1_std']:.4f}\")\n",
    "\n",
    "if 'binary_link_prediction' in downstream_results:\n",
    "    r = downstream_results['binary_link_prediction']\n",
    "    print(\"\\nBinary Link Prediction:\")\n",
    "    print(f\"  Test AUC: {r['test_auc_mean']:.4f} ± {r['test_auc_std']:.4f}\")\n",
    "    print(f\"  Test AP:  {r['test_ap_mean']:.4f} ± {r['test_ap_std']:.4f}\")\n",
    "\n",
    "if 'multiclass_link_prediction' in downstream_results:\n",
    "    r = downstream_results['multiclass_link_prediction']\n",
    "    print(\"\\nMulti-Label Prediction:\")\n",
    "    print(f\"  Test F1 (micro): {r['test_f1_micro_mean']:.4f} ± {r['test_f1_micro_std']:.4f}\")\n",
    "    print(f\"  Test F1 (macro): {r['test_f1_macro_mean']:.4f} ± {r['test_f1_macro_std']:.4f}\")\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    metrics = []\n",
    "    values = []\n",
    "    errors = []\n",
    "    \n",
    "    if 'node_classification' in downstream_results:\n",
    "        node_results = downstream_results['node_classification']\n",
    "        if 'test_acc_mean' in node_results:\n",
    "            metrics.append('Node Acc')\n",
    "            values.append(node_results['test_acc_mean'])\n",
    "            errors.append(node_results['test_acc_std'])\n",
    "    \n",
    "    if 'binary_link_prediction' in downstream_results:\n",
    "        link_results = downstream_results['binary_link_prediction']\n",
    "        if 'test_auc_mean' in link_results:\n",
    "            metrics.append('Link AUC')\n",
    "            values.append(link_results['test_auc_mean'])\n",
    "            errors.append(link_results['test_auc_std'])\n",
    "        if 'test_ap_mean' in link_results:\n",
    "            metrics.append('Link AP')\n",
    "            values.append(link_results['test_ap_mean'])\n",
    "            errors.append(link_results['test_ap_std'])\n",
    "    \n",
    "    if 'multiclass_link_prediction' in downstream_results:\n",
    "        multiclass_results = downstream_results['multiclass_link_prediction']\n",
    "        if 'test_f1_micro_mean' in multiclass_results:\n",
    "            metrics.append('Multi-Label F1')\n",
    "metrics, values, errors = [], [], []\n",
    "if 'node_classification' in downstream_results:\n",
    "    r = downstream_results['node_classification']\n",
    "    metrics.append('Node Acc')\n",
    "    values.append(r['test_acc_mean'])\n",
    "    errors.append(r['test_acc_std'])\n",
    "if 'binary_link_prediction' in downstream_results:\n",
    "    r = downstream_results['binary_link_prediction']\n",
    "    metrics.extend(['Link AUC', 'Link AP'])\n",
    "    values.extend([r['test_auc_mean'], r['test_ap_mean']])\n",
    "    errors.extend([r['test_auc_std'], r['test_ap_std']])\n",
    "if 'multiclass_link_prediction' in downstream_results:\n",
    "    r = downstream_results['multiclass_link_prediction']\n",
    "    metrics.append('Multi-Label F1')\n",
    "    values.append(r['test_f1_micro_mean'])\n",
    "    errors.append(r['test_f1_micro_std'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(metrics, values, yerr=errors, capsize=5, alpha=0.8)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_ylim(0, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphSSL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
